{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96fdfb-f252-418c-9f19-dd71440f65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ§  LLM Reasoning & Personality Knowledge Graph Challenge\n",
    "# Notebook: 01_pipeline.ipynb\n",
    "# Author: Onyekachukwu Ekesi\n",
    "# Description: End-to-end pipeline to extract knowledge graph and model personalities from text.\n",
    "\n",
    "# %%\n",
    "# ðŸ“¦ Import libraries\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9cbfb4-09e5-497f-86b0-268ad19cc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# %%\n",
    "# ðŸ§© Step 1: Generate synthetic dataset\n",
    "# In a real scenario, LLM (ChatGPT/OpenAI API) can generate bios automatically.\n",
    "# For simplicity, we define a few synthetic examples here.\n",
    "\n",
    "synthetic_bios = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"text\": \"John is a dedicated software engineer at Intellumia. He loves solving problems, mentoring juniors, and spends weekends volunteering. He is known for being very organized and dependable.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"text\": \"Mary is an artist who enjoys exploring new ideas and meeting people. She works independently, often collaborates with international designers, and has a cheerful personality.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"text\": \"David, a financial analyst at NovaCorp, prefers working alone on complex models. Though introverted, he is analytical, precise, and sometimes anxious about deadlines.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(synthetic_bios)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7049b-889b-4e0d-8a8b-9fe966f6ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ’¬ Step 2: Named Entity Recognition (NER) using spaCy\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "df[\"entities\"] = df[\"text\"].apply(extract_entities)\n",
    "df[[\"id\", \"entities\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48af88-f2de-4356-9968-e2fc6018bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ”— Step 3: Relation Extraction (Rule-based mockup)\n",
    "# Here, we simulate relationship triples: (subject, relation, object)\n",
    "\n",
    "def extract_relations(text):\n",
    "    relations = []\n",
    "    if \"engineer\" in text:\n",
    "        relations.append((\"John\", \"works_as\", \"Software Engineer\"))\n",
    "    if \"artist\" in text:\n",
    "        relations.append((\"Mary\", \"works_as\", \"Artist\"))\n",
    "    if \"analyst\" in text:\n",
    "        relations.append((\"David\", \"works_as\", \"Financial Analyst\"))\n",
    "    if \"Intellumia\" in text:\n",
    "        relations.append((\"John\", \"works_at\", \"Intellumia\"))\n",
    "    if \"NovaCorp\" in text:\n",
    "        relations.append((\"David\", \"works_at\", \"NovaCorp\"))\n",
    "    return relations\n",
    "\n",
    "df[\"relations\"] = df[\"text\"].apply(extract_relations)\n",
    "df[[\"id\", \"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd3186-3cdf-4797-9261-959b3d360179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ§¬ Step 4: Simulated LLM Personality Inference\n",
    "# This step would normally use a chain of LLM prompts to infer Big Five traits.\n",
    "# For now, we'll simulate it using keyword cues.\n",
    "\n",
    "def infer_personality(text):\n",
    "    traits = {\n",
    "        \"Openness\": 0.5,\n",
    "        \"Conscientiousness\": 0.5,\n",
    "        \"Extraversion\": 0.5,\n",
    "        \"Agreeableness\": 0.5,\n",
    "        \"Neuroticism\": 0.5,\n",
    "    }\n",
    "\n",
    "    cues = {\n",
    "        \"organized\": (\"Conscientiousness\", +0.3),\n",
    "        \"dependable\": (\"Conscientiousness\", +0.2),\n",
    "        \"cheerful\": (\"Extraversion\", +0.3),\n",
    "        \"introverted\": (\"Extraversion\", -0.3),\n",
    "        \"analytical\": (\"Openness\", +0.3),\n",
    "        \"anxious\": (\"Neuroticism\", +0.4),\n",
    "        \"volunteering\": (\"Agreeableness\", +0.3),\n",
    "        \"exploring\": (\"Openness\", +0.2),\n",
    "    }\n",
    "\n",
    "    for word, (trait, effect) in cues.items():\n",
    "        if word in text.lower():\n",
    "            traits[trait] += effect\n",
    "\n",
    "    # Clamp between 0 and 1\n",
    "    for trait in traits:\n",
    "        traits[trait] = max(0, min(1, traits[trait]))\n",
    "\n",
    "    return traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd26d6-461b-4715-aeb3-b897b9852ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"personality\"] = df[\"text\"].apply(infer_personality)\n",
    "df[[\"id\", \"personality\"]].apply(lambda x: pprint(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf805b5-7e0c-402f-a4db-6dd887374d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸŒ Step 5: Build Knowledge Graph\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    person_name = row[\"text\"].split()[0]  # crude name extraction\n",
    "    G.add_node(person_name, type=\"Person\")\n",
    "\n",
    "    # Add profession relations\n",
    "    for (subj, rel, obj) in row[\"relations\"]:\n",
    "        G.add_node(obj, type=\"Entity\")\n",
    "        G.add_edge(subj, obj, relation=rel)\n",
    "\n",
    "    # Add personality trait nodes\n",
    "    for trait, score in row[\"personality\"].items():\n",
    "        trait_node = f\"{person_name}_{trait}\"\n",
    "        G.add_node(trait_node, type=\"Trait\", score=score)\n",
    "        G.add_edge(person_name, trait_node, relation=\"has_trait\", weight=score)\n",
    "\n",
    "# Export to GraphML\n",
    "nx.write_graphml(G, \"data/output/knowledge_graph.graphml\")\n",
    "\n",
    "print(f\"Graph has {len(G.nodes())} nodes and {len(G.edges())} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde98a8-a42b-479a-82e0-d54d8f1fd516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ§­ Step 6: Inspect sample triples\n",
    "for u, v, d in list(G.edges(data=True))[:10]:\n",
    "    print(f\"{u} -[{d['relation']}]-> {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab36d0f-2f17-4c0d-8683-ffef8bd28439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ“Š Step 7: Evaluate (Simple Mock Evaluation)\n",
    "\n",
    "# Assume ground truth personality scores (for demonstration)\n",
    "ground_truth = {\n",
    "    \"John\": {\"Conscientiousness\": 0.8, \"Agreeableness\": 0.7},\n",
    "    \"Mary\": {\"Extraversion\": 0.8, \"Openness\": 0.7},\n",
    "    \"David\": {\"Neuroticism\": 0.7, \"Openness\": 0.6},\n",
    "}\n",
    "\n",
    "def simple_eval(pred, truth):\n",
    "    results = []\n",
    "    for person, traits in truth.items():\n",
    "        pred_traits = pred.loc[df[\"text\"].str.contains(person), \"personality\"].iloc[0]\n",
    "        for t, val in traits.items():\n",
    "            diff = abs(pred_traits.get(t, 0.5) - val)\n",
    "            results.append({\"Person\": person, \"Trait\": t, \"Error\": round(diff, 2)})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "eval_df = simple_eval(df, ground_truth)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581d0c6-a1d6-4c43-a7c5-3c277033bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ðŸ’¾ Step 8: Save results\n",
    "df.to_json(\"data/output/results.json\", orient=\"records\", indent=2)\n",
    "eval_df.to_csv(\"data/output/evaluation.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Pipeline completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d51c66-b42b-46ea-8488-120e08ed625c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07102347-c43e-42e8-95a3-297a798f535a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd68b98-0650-40f5-88aa-9381be61e812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69c0a1-26f7-4d7d-a07a-98bb11de680e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
